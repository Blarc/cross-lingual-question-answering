{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Checking for translated answers in the translated context\n",
    "\n",
    "The purpose of this notebook is to check if the translation of the answer exists in the translated context.\n",
    "This is done by extracting N-grams, transforming them to word embeddings using fasttext model and\n",
    "calculating cosine similarity between them.\n",
    "\n",
    "The algorithm is described in an article called \n",
    "[Sentence Similarity Techniques for Short vs Variable Length Text using Word Embeddings](https://www.researchgate.net/publication/338283181_Sentence_Similarity_Techniques_for_Short_vs_Variable_Length_Text_using_Word_Embeddings)\n",
    "by *Dudekula, Shashavali & Vishwjeet, V. & Kumar, Rahul & Mathur, Gaurav & Nihal, Nikhil & Mukherjee, Siddhartha & Patil, Suresh (2019)\n",
    "Computación y Sistemas. 23. 10.13053/cys-23-3-3273*. \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "----\n",
    "First we load prepared fasttext model that we will use for creating word embeddings."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "model = fasttext.load_model('../../models/fasttext_train_model.bin')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "----\n",
    "Function `get_grams(text)` takes text as an input and returns N-grams, which are consecutive strings\n",
    "of N words."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "def get_grams(text, n = 3):\n",
    "    text_split = text.split()\n",
    "    for i_ in range(1, n + 1):\n",
    "        yield ngrams(text_split, i_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "----\n",
    "Function `grams_to_embeddings(grams, model_)` transforms N-grams to word embeddings that are needed for\n",
    "calculating similarity between N-grams."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def grams_to_embeddings(grams, model_):\n",
    "    result = []\n",
    "    for gram in grams:\n",
    "        ngram = gram[0]\n",
    "        for w in gram[1:]:\n",
    "            ngram += f' {w}'\n",
    "        result.append(model_.get_sentence_vector(ngram))\n",
    "    return result\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "----\n",
    "Function `average_similarity(query_embeddings, context_embeddings)` calculates cosine similarity between\n",
    "all combinations of N-grams and returns the starting index of the similar text in the context and\n",
    "average cosine similarity."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def average_similarity(query_embeddings, context_embeddings):\n",
    "    \n",
    "    if len(query_embeddings) == 0:\n",
    "        return -1, -1\n",
    "        \n",
    "    unigrams_similarities = cosine_similarity(query_embeddings, context_embeddings)\n",
    "    \n",
    "    indexes = []\n",
    "    max_similarities = []\n",
    "    for similarity_matrix in unigrams_similarities:\n",
    "        argmax = np.argmax(similarity_matrix)\n",
    "        indexes.append(argmax)\n",
    "        max_similarities.append(similarity_matrix[argmax])\n",
    "    \n",
    "    return indexes[0], sum(max_similarities) / len(max_similarities)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "----\n",
    "Function `find_similar_text(query, text, fasttext_model)` just runs the calculation of,\n",
    "similarity for different N-grams and reports the results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def find_similar_text(query, text, fasttext_model, n = 3):\n",
    "    average_similarities = []\n",
    "    for query_grams, text_grams in zip(get_grams(query, n), get_grams(text, n)):\n",
    "        answer_unigrams_embeddings = grams_to_embeddings(query_grams, fasttext_model)\n",
    "        context_unigrams_embeddings = grams_to_embeddings(text_grams, fasttext_model)\n",
    "        average_similarities.append(average_similarity(answer_unigrams_embeddings, context_unigrams_embeddings))\n",
    "\n",
    "    return average_similarities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Normani 1: (Norman: 2: Nourmands; 3: Francoščina: 4: Normandi; 5: Latinščina: 6: Normanni) 7: so 8: bili 9: ljudje, 10: ki 11: so 12: v 13: 10. 14: in 15: 11. 16: stoletju 17: dali 18: ime 19: Normandiji, 20: regiji 21: v 22: Franciji. 23: Bili 24: so 25: potomci 26: nordijskih 27: plenilcev 28: in 29: piratov 30: iz 31: Danske, 32: Islandije 33: in 34: Norveške, 35: ki 36: so 37: pod 38: svojim 39: voditeljem 40: Rollom 41: prisegli 42: zvestobo 43: kralju 44: Karlu 45: III. 46: iz 47: Zahodne 48: Frankovske. 49: Skozi 50: generacije 51: asimilacije 52: in 53: mešanja 54: z 55: domačimi 56: frankovskimi 57: in 58: rimsko-gavskimi 59: populacijami 60: so 61: se 62: njihovi 63: potomci 64: postopoma 65: združili 66: s 67: karolinškimi 68: kulturami 69: Zahodne 70: Frankovske. 71: Posebna 72: kulturna 73: in 74: etnična 75: identiteta 76: Normanov 77: se 78: je 79: sprva 80: pojavila 81: v 82: prvi 83: polovici 84: 10. 85: stoletja 86: in 87: se 88: je 89: razvijala 90: v 91: naslednjih 92: stoletjih. "
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('../../data/dev-v2.0_SL.json', 'r', encoding='UTF-8') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "context = data[0]['paragraphs'][0]['context']\n",
    "for ix, i in enumerate(next(get_grams(context))):\n",
    "    for word in i:\n",
    "        print(f'{ix}: {word}', end=' ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V kateri državi se nahaja Normandija?\n",
      "Francija\n",
      "(22, 0.7197608947753906)\n",
      "(-1, -1)\n",
      "(-1, -1)\n",
      "Kdaj so bili Normani v Normandiji?\n",
      "10. in 11. stoletje\n",
      "(13, 0.9646217525005341)\n",
      "(13, 0.9829012950261434)\n",
      "(13, 0.9859484136104584)\n",
      "Iz katerih držav je Norveška izvirala?\n",
      "Danska, Islandija in Norveška\n",
      "(31, 0.7949058413505554)\n",
      "(31, 0.8514732718467712)\n",
      "(31, 0.857131153345108)\n"
     ]
    }
   ],
   "source": [
    "qas_number = 0\n",
    "answer = data[0]['paragraphs'][0]['qas'][qas_number]['answers'][0]['text']\n",
    "question = data[0]['paragraphs'][0]['qas'][qas_number]['question']        \n",
    "print(question)\n",
    "print(answer)\n",
    "for similarity in find_similar_text(answer, context, model):\n",
    "    print(similarity)\n",
    "\n",
    "qas_number = 1\n",
    "answer = data[0]['paragraphs'][0]['qas'][qas_number]['answers'][0]['text']\n",
    "question = data[0]['paragraphs'][0]['qas'][qas_number]['question']      \n",
    "print(question)\n",
    "print(answer)\n",
    "for similarity in find_similar_text(answer, context, model):\n",
    "    print(similarity)\n",
    "\n",
    "qas_number = 2\n",
    "answer = data[0]['paragraphs'][0]['qas'][qas_number]['answers'][0]['text']\n",
    "question = data[0]['paragraphs'][0]['qas'][qas_number]['question']      \n",
    "print(question)\n",
    "print(answer)\n",
    "for similarity in find_similar_text(answer, context, model):\n",
    "    print(similarity)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}