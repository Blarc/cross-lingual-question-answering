{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/matic/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/matic/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../results/xlm-roberta-large\n",
      "average cosine similarity:  0.27132635811640327\n",
      "average precision:  0.2711790404040404\n",
      "average recall:  0.3447335248085248\n",
      "average f1-score:  0.234150974025974\n",
      "\n",
      "../../results/xlm-roberta-base-whole-dataset-3-epochs-best\n",
      "average cosine similarity:  0.6360413519925228\n",
      "average precision:  0.6633487098821107\n",
      "average recall:  0.6835816217060263\n",
      "average f1-score:  0.5703276573588417\n",
      "\n",
      "../../results/multilingual-bert-uncased-slo-fixed\n",
      "average cosine similarity:  0.26720310478404113\n",
      "average precision:  0.26461127483627483\n",
      "average recall:  0.35810847763347764\n",
      "average f1-score:  0.2401334498834499\n",
      "\n",
      "../../results/xlm-roberta-base-whole-dataset-1-epoch\n",
      "average cosine similarity:  0.6107070162141742\n",
      "average precision:  0.6359819537917236\n",
      "average recall:  0.6615237186340425\n",
      "average f1-score:  0.546423321703683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folders = [ f.path for f in os.scandir(\"../../results\") if f.is_dir() ]\n",
    "\n",
    "for fname in folders:\n",
    "\n",
    "    DATADIR     = fname + \"/\"\n",
    "    PREDICTIONS = DATADIR + \"predictions.json\"\n",
    "    REFERENCES  = DATADIR + \"references.json\"\n",
    "\n",
    "    try:\n",
    "        predictions = open(PREDICTIONS)\n",
    "    except:\n",
    "        continue\n",
    "    references  = open(REFERENCES)\n",
    "\n",
    "    pjson = json.load(predictions)\n",
    "    rjson = json.load(references)\n",
    "\n",
    "    similarities = []\n",
    "    recalls = []\n",
    "    precisions = []\n",
    "    f1s = []\n",
    "    errors = 0\n",
    "\n",
    "    for i in range(len(pjson)):\n",
    "        pred = pjson[i]['prediction_text']\n",
    "        refs  = rjson[i]['answers']['text']\n",
    "\n",
    "        X_list = word_tokenize(pred)\n",
    "\n",
    "        sim = 0\n",
    "\n",
    "        for ref in refs:\n",
    "            #print(\"Prediction: \", pred)\n",
    "            #print(\"Reference: \", ref)\n",
    "\n",
    "            Y_list = word_tokenize(ref)\n",
    "            \n",
    "            # sw contains the list of stopwords\n",
    "            sw = stopwords.words('slovene') \n",
    "            l1 =[];l2 =[]\n",
    "            \n",
    "            # remove stop words from the string\n",
    "            X_set = {w for w in X_list if not w in sw} \n",
    "            Y_set = {w for w in Y_list if not w in sw}\n",
    "            \n",
    "            # form a set containing keywords of both strings \n",
    "            rvector = X_set.union(Y_set) \n",
    "            for w in rvector:\n",
    "                if w in X_set: l1.append(1) # create a vector\n",
    "                else: l1.append(0)\n",
    "                if w in Y_set: l2.append(1)\n",
    "                else: l2.append(0)\n",
    "            c = 0\n",
    "            \n",
    "            # cosine formula \n",
    "            for i in range(len(rvector)):\n",
    "                    c+= l1[i]*l2[i]\n",
    "            if float((sum(l1)*sum(l2))**0.5) == 0:\n",
    "                errors += 1\n",
    "                break\n",
    "            cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
    "            #print(\"similarity: \", cosine)\n",
    "\n",
    "            if cosine > sim:\n",
    "                sim = cosine\n",
    "\n",
    "        similarities.append(sim)\n",
    "            \n",
    "        #print(pred)\n",
    "        #print(refs)\n",
    "\n",
    "    for i in range(len(pjson)):\n",
    "        pred = pjson[i]['prediction_text']\n",
    "        refs  = rjson[i]['answers']['text']\n",
    "\n",
    "        p = word_tokenize(pred)\n",
    "\n",
    "        prec = 0\n",
    "        rec = 0\n",
    "        f = 0\n",
    "\n",
    "        for ref in refs:\n",
    "            #print(\"Prediction: \", pred)\n",
    "            #print(\"Reference: \", ref)\n",
    "\n",
    "            r = word_tokenize(ref)\n",
    "            \n",
    "            # sw contains the list of stopwords\n",
    "            sw = stopwords.words('slovene') \n",
    "            l1 =[];l2 =[]\n",
    "            \n",
    "            # remove stop words from the string\n",
    "            pset = {w for w in p if not w in sw} \n",
    "            rset = {w for w in r if not w in sw}\n",
    "\n",
    "            common_tokens = pset & rset\n",
    "\n",
    "            if len(pset) == 0 or len(rset) == 0:\n",
    "                if len(pset) == len(rset):\n",
    "                    prec = 1\n",
    "                    rec = 1\n",
    "                    f = 0\n",
    "                    break\n",
    "            else:\n",
    "                precision = len(common_tokens) / len(pset)\n",
    "                recall = len(common_tokens) / len(rset)\n",
    "\n",
    "            if precision + recall == 0:\n",
    "                f1 = 0\n",
    "            else:\n",
    "                f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "            if f1 > f:\n",
    "                f = f1\n",
    "                prec = precision\n",
    "                rec = recall\n",
    "\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    print(fname)\n",
    "    print(\"average cosine similarity: \", np.average(np.array(similarities)))\n",
    "    print(\"average precision: \", np.average(np.array(precisions)))\n",
    "    print(\"average recall: \", np.average(np.array(recalls)))\n",
    "    print(\"average f1-score: \", np.average(np.array(f1s)))\n",
    "    print()\n",
    "\n",
    "\n",
    "    predictions.close()\n",
    "    references.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
